{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypdf\n",
    "import matplotlib.pyplot as plt\n",
    "import tabula\n",
    "import zipfile\n",
    "\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.utils.download import download_file_from_url\n",
    "from src.utils.plot import plot_bar, plot_hist, plot_pie\n",
    "from src.utils.states import abbrev_to_state\n",
    "\n",
    "INPUT_DATA_DIR = \"./input_data\"\n",
    "OUTPUT_IMAGE_DIR = \"./images/pa_claims\"\n",
    "OUTPUT_DATA_DIR = \"./output_data/pa_claims\"  # Set to None if you don't want to save non-required data for external use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(INPUT_DATA_DIR, exist_ok=True)\n",
    "if OUTPUT_IMAGE_DIR:\n",
    "    os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
    "if OUTPUT_DATA_DIR:\n",
    "    os.makedirs(OUTPUT_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issuer_data(pdf_path):\n",
    "    # Get issuer level data from first page\n",
    "    issuer1_area = (171, 51, 562, 378)\n",
    "    issuer1 = tabula.read_pdf(pdf_path, pages=1, area=issuer1_area)[0]\n",
    "    plan_year_reporting = int(issuer1.iloc[0, 0][-6:-2])\n",
    "    plan_year = plan_year_reporting + 2\n",
    "\n",
    "    # Get issuer level data from second page\n",
    "    issuer2_area = (171, 51, 600, 378)\n",
    "    issuer2 = tabula.read_pdf(\n",
    "        pdf_path,\n",
    "        pages=2,\n",
    "        area=issuer2_area,\n",
    "        multiple_tables=False,\n",
    "        stream=True,\n",
    "        pandas_options={\"header\": None},\n",
    "    )[0]\n",
    "\n",
    "    # Get metadata values\n",
    "    issuer_values = issuer2.iloc[:, 0].values\n",
    "    on_exchange_in_plan_year_reporting = True if issuer_values[0] == \"Yes\" else False\n",
    "    sadp_only = True if issuer_values[1] == \"Yes\" else False\n",
    "    hios_issuer_id = int(issuer_values[2])\n",
    "\n",
    "    # Claims\n",
    "    claims_received = (\n",
    "        int(issuer_values[3].replace(\",\", \"\"))\n",
    "        if not pd.isna(issuer_values[3])\n",
    "        else None\n",
    "    )\n",
    "    claims_denied = (\n",
    "        int(issuer_values[4].replace(\",\", \"\"))\n",
    "        if not pd.isna(issuer_values[4])\n",
    "        else None\n",
    "    )\n",
    "    internal_appeals = (\n",
    "        int(issuer_values[5].replace(\",\", \"\"))\n",
    "        if not pd.isna(issuer_values[5])\n",
    "        else None\n",
    "    )\n",
    "    internal_appeal_overturns = (\n",
    "        int(issuer_values[6].replace(\",\", \"\"))\n",
    "        if not pd.isna(issuer_values[6])\n",
    "        else None\n",
    "    )\n",
    "    external_appeals = (\n",
    "        int(issuer_values[7].replace(\",\", \"\"))\n",
    "        if not pd.isna(issuer_values[7])\n",
    "        else None\n",
    "    )\n",
    "    external_appeal_overturns = (\n",
    "        int(issuer_values[8].replace(\",\", \"\"))\n",
    "        if not pd.isna(issuer_values[8])\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        hios_issuer_id,\n",
    "        plan_year,\n",
    "        plan_year_reporting,\n",
    "        sadp_only,\n",
    "        claims_received,\n",
    "        claims_denied,\n",
    "        internal_appeals,\n",
    "        internal_appeal_overturns,\n",
    "        external_appeals,\n",
    "        external_appeal_overturns,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_comma_string_to_int(val):\n",
    "    if type(val) is not str:\n",
    "        val = str(val)\n",
    "        val = val.replace(\".0\", \"\")\n",
    "    # Remove commas in strs, and erroneous str entries\n",
    "    val = int(val.replace(\",\", \"\")) if val != \"N/A\" else None\n",
    "    return val\n",
    "\n",
    "\n",
    "def get_plan_data(pdf_path, plan_year, issuer_id):\n",
    "    # Get total pdf page length\n",
    "    reader = pypdf.PdfReader(open(pdf_path, mode=\"rb\"))\n",
    "    num_pages = len(reader.pages)\n",
    "\n",
    "    if num_pages < 3:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Hardcode starting page in pdfs for plan-level data\n",
    "    start_page = 3\n",
    "\n",
    "    p_area = (171, 51, 800, 378)\n",
    "    plans = tabula.read_pdf(\n",
    "        pdf_path,\n",
    "        pages=f\"{start_page}-{num_pages}\",\n",
    "        guess=False,\n",
    "        lattice=True,\n",
    "        multiple_tables=True,\n",
    "        pandas_options={\"header\": None},\n",
    "    )\n",
    "\n",
    "    plan_dfs = []\n",
    "\n",
    "    # We will iterate over vertically split pieces within horizontally split pieces\n",
    "    # Table is split horizontally into 3 pieces.\n",
    "    # Number of vertical pieces for each horizontal piece varies by pdf, depending on total num records in table\n",
    "    horizontal_pieces = 3\n",
    "    assert len(plans) % horizontal_pieces == 0\n",
    "    num_vertical_pieces = len(plans) // horizontal_pieces\n",
    "\n",
    "    # Subsequent pages can be handled with consistent logic\n",
    "    # Since no need to drop a row\n",
    "    for pg_num in range(0, len(plans), num_vertical_pieces):\n",
    "        vertical_pieces = []\n",
    "        for voffset in range(0, num_vertical_pieces):\n",
    "            p = plans[pg_num + voffset]\n",
    "            if voffset == 0:\n",
    "                if pg_num == 0:\n",
    "                    p = p.drop(labels=0, axis=0).reset_index(drop=True)\n",
    "                p.columns = p.iloc[0]\n",
    "                p = p.drop(axis=0, labels=0)\n",
    "            vertical_pieces.append(p)\n",
    "        vertical_piece = pd.DataFrame(np.vstack(vertical_pieces))\n",
    "        vertical_piece.columns = vertical_pieces[0].columns\n",
    "        plan_dfs.append(vertical_piece)\n",
    "\n",
    "    # Drop complete NA dfs that appear\n",
    "    plan_dfs = [df for df in plan_dfs if not df.isnull().values.all()]\n",
    "\n",
    "    # Drop complete NA rows\n",
    "    df = pd.concat(plan_dfs, axis=1).dropna(how=\"all\")\n",
    "\n",
    "    # Add plan year column\n",
    "    df[\"current_plan_year\"] = plan_year\n",
    "    df[\"data_plan_year\"] = plan_year - 2\n",
    "\n",
    "    # Add issuer id column\n",
    "    df[\"hios_issuer_id\"] = issuer_id\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = [\n",
    "        \"plan_id\",\n",
    "        \"claims_received\",\n",
    "        \"claims_denied\",\n",
    "        \"claims_denied_prior_auth_referral\",\n",
    "        \"claims_denied_oon_provider\",\n",
    "        \"claims_denied_exclusion_of_service\",\n",
    "        \"claims_denied_nmn_excl_behavioral\",\n",
    "        \"claims_denied_nmn_behavioral\",\n",
    "        \"claims_denied_other\",\n",
    "        \"notes\",\n",
    "        \"current_plan_year\",\n",
    "        \"data_plan_year\",\n",
    "        \"hios_issuer_id\",\n",
    "    ]\n",
    "\n",
    "    # Cast int cols\n",
    "    int_cols = [\n",
    "        \"claims_received\",\n",
    "        \"claims_denied\",\n",
    "        \"claims_denied_prior_auth_referral\",\n",
    "        \"claims_denied_oon_provider\",\n",
    "        \"claims_denied_exclusion_of_service\",\n",
    "        \"claims_denied_nmn_excl_behavioral\",\n",
    "        \"claims_denied_nmn_behavioral\",\n",
    "        \"claims_denied_other\",\n",
    "    ]\n",
    "    for int_col in int_cols:\n",
    "        df[int_col] = (\n",
    "            df[int_col].apply(convert_comma_string_to_int).astype(dtype=\"Int64\")\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/mike/persius/Public Records Request/PA/rtkl01609\"\n",
    "pdf_paths = glob.glob(f\"{data_dir}/**\")\n",
    "\n",
    "\n",
    "# Issuer level, plan year claims denial data format:\n",
    "insurer_names = []\n",
    "issuer_hios_ids = []\n",
    "plan_years_reporting = []\n",
    "plan_years = []\n",
    "sadp_only_statuses = []\n",
    "claims_received = []  # received and DOS in plan_year\n",
    "claims_denied = []\n",
    "internal_appeals = []\n",
    "internal_appeal_overturns = []\n",
    "external_appeals = []\n",
    "external_appeal_overturns = []\n",
    "plan_dfs = []\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    try:\n",
    "        insurer_name = \" \".join(pdf_path.split(\"/\")[-1].split(\"-\")[0].split(\" \")[:-1])\n",
    "\n",
    "        # Get insurer-level data\n",
    "        (\n",
    "            hios_issuer_id,\n",
    "            plan_year,\n",
    "            plan_year_reporting,\n",
    "            sadp_only,\n",
    "            issuer_claims_received,\n",
    "            issuer_claims_denied,\n",
    "            issuer_internal_appeals,\n",
    "            issuer_internal_appeal_overturns,\n",
    "            issuer_external_appeals,\n",
    "            issuer_external_appeal_overturns,\n",
    "        ) = get_issuer_data(pdf_path)\n",
    "\n",
    "        # Append insurer-level data\n",
    "        insurer_names.append(insurer_name)\n",
    "        issuer_hios_ids.append(hios_issuer_id)\n",
    "        plan_years_reporting.append(plan_year_reporting)\n",
    "        plan_years.append(plan_year)\n",
    "        sadp_only_statuses.append(sadp_only)\n",
    "        claims_received.append(issuer_claims_received)\n",
    "        claims_denied.append(issuer_claims_denied)\n",
    "        internal_appeals.append(issuer_internal_appeals)\n",
    "        internal_appeal_overturns.append(issuer_internal_appeal_overturns)\n",
    "        external_appeals.append(issuer_external_appeals)\n",
    "        external_appeal_overturns.append(issuer_external_appeal_overturns)\n",
    "\n",
    "        # Get plan-level data\n",
    "        plan_data = get_plan_data(\n",
    "            pdf_path, plan_year=plan_year, issuer_id=hios_issuer_id\n",
    "        )\n",
    "        if len(plan_data) > 0:\n",
    "            plan_dfs.append(plan_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(pdf_path)\n",
    "        print(e)\n",
    "\n",
    "issuer_df = pd.DataFrame(\n",
    "    data={\n",
    "        \"insurer_name\": pd.Series(insurer_names, dtype=str),\n",
    "        \"hios_id\": pd.Series(issuer_hios_ids, dtype=int),\n",
    "        \"data_plan_year\": pd.Series(plan_years_reporting, dtype=int),\n",
    "        \"current_plan_year\": pd.Series(plan_years, dtype=int),\n",
    "        \"sadp_only\": sadp_only_statuses,\n",
    "        \"claims_received\": pd.Series(claims_received, dtype=\"Int64\"),\n",
    "        \"claims_denied\": pd.Series(claims_denied, dtype=\"Int64\"),\n",
    "        \"internal_appeals\": pd.Series(internal_appeals, dtype=\"Int64\"),\n",
    "        \"internal_appeal_overturns\": pd.Series(\n",
    "            internal_appeal_overturns, dtype=\"Int64\"\n",
    "        ),\n",
    "        \"external_appeals\": pd.Series(external_appeals, dtype=\"Int64\"),\n",
    "        \"external_appeal_overturns\": pd.Series(\n",
    "            external_appeal_overturns, dtype=\"Int64\"\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "plan_df = pd.concat(plan_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "issuer_df.to_csv(os.path.join(OUTPUT_DATA_DIR, \"issuers.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_df.to_csv(os.path.join(OUTPUT_DATA_DIR, \"plans.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('investigations')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ae921485ccdeea0c9537f4676470eee0f383b03f998fe345bd7062257fee1e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
